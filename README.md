## Prototype Development for Image Captioning Using the BLIP Model and Gradio Framework

### AIM:
To design and deploy a prototype application for image captioning by utilizing the BLIP image-captioning model and integrating it with the Gradio UI framework for user interaction and evaluation.

### PROBLEM STATEMENT:
Create a web application allowing users to upload an image and receive a descriptive caption generated by the state-of-the-art BLIP model.

### DESIGN STEPS:

#### STEP 1:
Install libraries; secure API key for model access.

#### STEP 2:
Define function to send image to API, get caption.

#### STEP 3:
Create utility to convert PIL image to base64 string.

#### STEP 4:
Write captioner function to process image and call API.

#### STEP 5:
Build Gradio interface with Image Input, Text Output.

#### STEP 6:
Launch the application and verify captioning functionality.

### PROGRAM:

```
import os
import io
import IPython.display
from PIL import Image
import base64 
from dotenv import load_dotenv, find_dotenv
_ = load_dotenv(find_dotenv()) # read local .env file
hf_api_key = os.environ['HF_API_KEY']
# Helper functions
import requests, json

#Image-to-text endpoint
def get_completion(inputs, parameters=None, ENDPOINT_URL=os.environ['HF_API_ITT_BASE']):
    headers = {
      "Authorization": f"Bearer {hf_api_key}",
      "Content-Type": "application/json"
    }
    data = { "inputs": inputs }
    if parameters is not None:
        data.update({"parameters": parameters})
    response = requests.request("POST",
                                ENDPOINT_URL,
                                headers=headers,
                                data=json.dumps(data))
    return json.loads(response.content.decode("utf-8"))
image_url = "https://free-images.com/lg/ada9/seekarspitze_von_achenkirch.jpg"
display(IPython.display.Image(url=image_url))
get_completion(image_url)
import gradio as gr 

def image_to_base64_str(pil_image):
    byte_arr = io.BytesIO()
    pil_image.save(byte_arr, format='PNG')
    byte_arr = byte_arr.getvalue()
    return str(base64.b64encode(byte_arr).decode('utf-8'))

def captioner(image):
    base64_image = image_to_base64_str(image)
    result = get_completion(base64_image)
    return result[0]['generated_text']

gr.close_all()
demo = gr.Interface(fn=captioner,
                    inputs=[gr.Image(label="Upload image", type="pil")],
                    outputs=[gr.Textbox(label="Caption")],
                    title="Image Captioning with BLIP",
                    description="Caption any image using the BLIP model",
                    allow_flagging="never",
                    examples=["halle_in_tirol_austria.jpg", "austria_hall_in_tirol.jpg"])

demo.launch(share=True, server_port=int(os.environ['PORT2']))

    
```

### OUTPUT:

<img width="1429" height="930" alt="image" src="https://github.com/user-attachments/assets/1c702af4-cf11-4012-bf1f-599615d72be3" />

<img width="1331" height="863" alt="image" src="https://github.com/user-attachments/assets/eb707dd8-42cb-40be-9f84-974fcff1bac1" />



### RESULT:
The BLIP model was successfully integrated with the Gradio framework, resulting in the deployment of a functional web application for image captioning.
